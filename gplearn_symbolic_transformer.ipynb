{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc1baa2",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "![iteso](https://upload.wikimedia.org/wikipedia/en/5/5f/Western_Institute_of_Technology_and_Higher_Education_logo.png)\n",
    "\n",
    "###  InstitutoTecnológico y de Estudios Superiores de Occidente ###\n",
    "###  Maestría Ciencia de Datos  ###\n",
    "###  Optimización Convexa ###\n",
    "###  HW 04: Optimización restringida y regularización (problema 2) ###\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "Estudiante: Daniel Nuño <br>\n",
    "Profesor: Dr. Juan Diego Sanchez Torres <br>\n",
    "Fecha entrega: 16 de febrero, 2022 <br>\n",
    "\n",
    "* * *\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37c3f4d6",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2af69",
   "metadata": {},
   "source": [
    "#### Introducción ####\n",
    "\n",
    "The purpose of this last activity is to solve a problem similar to those encountered in practice, using a reasonably sophisticated code structure appropriate to the solution of the problem. Also, use is made of symbolic transformers for the resolution of a regression problem. It is demonstrated that the use of new inputs can improve the model’s predictive capacity.\n",
    "\n",
    "#### Probelma 2 ####\n",
    "\n",
    "Read and reproduce the example about the Boston housing dataset given in [Gplearn: Symbolic Transformer](https://gplearn.readthedocs.io/en/stable/examples.html#symbolic-transformer). Then, explain how the symbolic transformer method helps to improve the regression’s performance. Upload your results to Github in the form of a Jupyter notebook, then make it interactive using Binder, hence submit your results through both links. The use of Google Colab is highly recommended.\n",
    "\n",
    "\n",
    "El ejemplo demuestra cómo crear nuevas variables no lineares usando `SymbolicTransformer` de la paquetería `gplearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fad0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab0e7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = check_random_state(0)\n",
    "boston = load_boston()\n",
    "perm = rng.permutation(boston.target.size)\n",
    "boston.data = boston.data[perm]\n",
    "boston.target = boston.target[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b25b52",
   "metadata": {},
   "source": [
    "Usando `Ridge` de `sklearn` se utilizará como base de comparación. Entrenas con las primeras 300 observaciones de boston usando Ridge y ves como desempeña con las finales 200 observaciones. El benchmark a batir es usando simplemente Ridge.\n",
    "\n",
    "La precisión que obtuvimos es 0.7593."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb49091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7593194530498838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "est = Ridge()\n",
    "est.fit(boston.data[:300, :], boston.target[:300])\n",
    "print(est.score(boston.data[300:, :], boston.target[300:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff56c74",
   "metadata": {},
   "source": [
    "En la siguiente celda, se entrena el transformador sobre las primeras 300 observaciones para generar nuevas variables.\n",
    "\n",
    "Un trasformador simbólico de Programación Genética es un transformador supervisado que comienza construyendo una población de fórmulas aleatorias ingenuas para representar una relación. Las fórmulas se representan como estructuras de forma de árbol con funciones matemáticas que se aplican recursivamente a variables y constantes. Luego, cada generación sucesiva de programas se desarrolla a partir de la anterior, seleccionando a los individuaos más aptos de la población para que se sometan a operaciones genéticas como el cruzamiento, la mutación o a la reproducción. La población final se busca los individuos más aptos con la menor correlación entre sí.\n",
    "\n",
    "Los argumentos que toma son los siguientes:<br>\n",
    "- `population_size:` es un número entero de programas en cada generación.<br>\n",
    "- `generations:` es el número de generaciones a evolucionar.<br>\n",
    "- `hall_of_fame:` es el número de los programas más aptos para comparar cuando se encuentren los individuos menos correlacionados para los *n_components*. Si es marcado como *None*, entonces toda la generación final sera usada.<br>\n",
    "- `n_components:` es el número de mejores programas para regresar después de buscar en *hall_of_fame* para los individuos menos correlacionados. Si *None* es indicado, entonces todo el *hall_of_fame* sera usado.<br>\n",
    "- `function_set:` las funciones que se utilizarán al crear y desarrollar programas. Este iterable puede incluir *strings* para indicar funciones individuales como se describe a continuación, o también puede incluir sus propias funciones creadas con la `make_function` del módulo `funciones`. En este ejemplo se utiliza suma, resta, multiplicación, división, raíz cuadrada, logaritmo natural, valor absoluto, negativos, inversa, máximos y mínimos.<br>\n",
    "- `parsimony_coefficient:` decimal o 'auto'. Esta constante penaliza los grandes programas ajustando su aptitud para que sean menos favorables para la selección. Los valores más grandes penalizan más al programa que puede controlar el fenómeno conocido como \"bloat\". Bloat es cuando la evolución aumenta el tamaño de los programas sin un aumento significativo en la aptitud, lo que es costoso para el tiempo de cálculo y hace que el resultado final sea menos comprensible. Es posible que este parámetro deba ajustarse en ejecuciones sucesivas.<br>\n",
    "- `max_samples:` es un número decimal que indica la fracción de muestras a sacar a partir de X a evaluar con cada programa.<br>\n",
    "- `random_state:` Si es un entero, random_state es la semilla utilizada por el generador de números aleatorios; Si es una instancia de RandomState, random_state es el generador de números aleatorios; Si es Ninguno, el generador de números aleatorios es la instancia de RandomState utilizada por np.random. <br>\n",
    "- `verbose:` sirve para imprimir los resultados del algoritmo al final de cada generación.<br>\n",
    "\n",
    "Así que ahora entrenaremos a nuestro transformador con las mismas primeras 300 muestras para generar características nuevas. Usemos una gran población de 2000 individuos durante 20 generaciones. Seleccionaremos los mejores 100 de estos para el salón de la fama y luego usaremos los 10 menos correlacionados como nuestras nuevas variables. Un poco de avaricia debería controlar el bloat, pero dejaremos el resto de las opciones de evolución en sus valores predeterminados. La métrica predeterminada = 'pearson' es apropiada aquí ya que estamos usando un modelo lineal como estimador. Si fuéramos a utilizar un estimador basado en árboles, también sería interesante probar la correlación de Spearman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f1b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    11.04         0.339876        6         0.822502         0.675124     24.78s\n",
      "   1     6.91         0.593562        7         0.836993         0.602468     22.55s\n",
      "   2     5.07         0.730093        8          0.84063         0.704017     21.91s\n",
      "   3     5.22         0.735525        5         0.847019         0.628351     21.53s\n",
      "   4     6.24         0.734679       10         0.856612         0.565138     19.41s\n",
      "   5     8.23         0.721433       18          0.85677         0.728095     17.97s\n",
      "   6    10.20         0.717937       14         0.875233         0.619693     19.22s\n",
      "   7    11.84         0.720667       14         0.875927         0.609363     16.53s\n",
      "   8    12.56         0.733019       27         0.881705         0.390121     15.77s\n",
      "   9    13.61          0.73144       16         0.873285         0.598466     14.56s\n",
      "  10    14.81         0.737687       16         0.873915          0.67127     13.31s\n",
      "  11    14.84          0.73787       21         0.874944         0.467722     12.41s\n",
      "  12    15.40         0.740935       22         0.878053         0.534554     11.92s\n",
      "  13    16.83         0.743265       15         0.874735         0.635764      9.02s\n",
      "  14    17.04         0.741628       13         0.884417         0.493354      7.44s\n",
      "  15    17.02         0.744034       26         0.892236         0.647918      6.33s\n",
      "  16    18.23         0.738467       43         0.879153         0.377872      4.57s\n",
      "  17    18.09         0.722973       16         0.889763         0.508006      3.06s\n",
      "  18    19.58          0.70793       27         0.889402         0.639016      1.55s\n",
      "  19    21.69         0.697116       24         0.888272          0.56025      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicTransformer(function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
       "                                  'abs', 'neg', 'inv', 'max', 'min'],\n",
       "                    max_samples=0.9, parsimony_coefficient=0.0005,\n",
       "                    population_size=2000, random_state=0, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                'abs', 'neg', 'inv', 'max', 'min']\n",
    "gp = SymbolicTransformer(generations=20, population_size=2000,\n",
    "                         hall_of_fame=100, n_components=10,\n",
    "                         function_set=function_set,\n",
    "                         parsimony_coefficient=0.0005,\n",
    "                         max_samples=0.9, verbose=1,\n",
    "                         random_state=0)\n",
    "gp.fit(boston.data[:300, :], boston.target[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f55047",
   "metadata": {},
   "source": [
    "Luego aplicaremos nuestro transformador entrenado a todo el conjunto de datos de Boston (recuerde, todavía no ha visto las 200 muestras finales) y lo concatenamos con los datos originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32fa7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_features = gp.transform(boston.data)\n",
    "new_boston = np.hstack((boston.data, gp_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7713b54",
   "metadata": {},
   "source": [
    "Ahora entrenamos el regresor de Ridge en las primeras 300 muestras del conjunto de datos transformado y vemos cómo se comporta nuevamente en las 200 finales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf3c13d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8418372105182075\n"
     ]
    }
   ],
   "source": [
    "est = Ridge()\n",
    "est.fit(new_boston[:300, :], boston.target[:300])\n",
    "print(est.score(new_boston[300:, :], boston.target[300:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3206fbf0",
   "metadata": {},
   "source": [
    "El resultado son 20 épocas o generaciones.\n",
    "- average_length: es el promedio de longitud de la generación.\n",
    "- average_fitness: es el promedio de aptitud de la generación.\n",
    "- best_length: la longitud del mejor programa en la generación.\n",
    "- best_fitness: la aptitud del mejor programa en la generación.\n",
    "- best_oob_fitness: *out of the bag* aptitud del mejor programa en la generación.\n",
    "\n",
    "La precisión con esta estimación es 0.84."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3911099",
   "metadata": {},
   "source": [
    "Hemos mejorado la puntuación R2 por un margen significativo. Parece que el modelo lineal pudo aprovechar algunas características no lineales nuevas para ajustar los datos aún mejor.\n",
    "\n",
    "Las nuevas características son, como lo habíamos mencionado 10. El total de columnas en *new_boston* son 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d19707ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 23)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_boston.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717fa5e",
   "metadata": {},
   "source": [
    "En conclusión, este algoritmo mejoró el resultado de la regresión lineal por que generó nuevas variables, de una forma *aleatoria e ingenua* evolutivamente. Dichas variables son las que aportaban mejores resultados son las que tienen menor correlacion entre si."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
